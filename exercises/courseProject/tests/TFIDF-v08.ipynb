{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from readingAndPreprocessingInput.ipynb\n"
     ]
    }
   ],
   "source": [
    "### imports\n",
    "import import_ipynb\n",
    "import readingAndPreprocessingInput as rp\n",
    "\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import CountVectorizer \n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Axial contrast-enhanced computed tomography scans prelenvatinib therapy (top left), 4 months postlenvatinib therapy (top middle), and 5 months post-surgery (top right). Note the 270-degree encirclement of the trachea by the left thyroid mass with potential membranous trachea and esophageal invasion prior to lenvatinib therapy (top left) timeline (middle) calcitonin and CEA concentrations versus time (bottom). CEA = carcinoembryonic antigen US = ultrasound.', 'Sagittal contrast-enhanced computed tomography scans prelenvatinib (left) and 4 months postlenvatinib therapy (right). Note the marked reduction in radiodensity (165.05 HU versus 61.54 HU) suggesting devascularization of the tumor. HU = Hounsfield unit.', 'A, Left hemithyroidectomy surgical specimen including left recurrent laryngeal nerve posteriorly and level VI lymph nodes. B, Left level VI/III metastatic lymph node. C, Left lateral lymphadenectomy specimen levels II, III, and IV.']\n",
      "Sagittal contrast-enhanced computed tomography scans prelenvatinib (left) and 4 months postlenvatinib therapy (right). Note the marked reduction in radiodensity (165.05 HU versus 61.54 HU) suggesting devascularization of the tumor. HU = Hounsfield unit.\n"
     ]
    }
   ],
   "source": [
    "def createDocList(corpus):\n",
    "    titlesList = []\n",
    "    captionsList = []\n",
    "    for doc in corpus:\n",
    "        titlesList.append(doc['articleTitle'])\n",
    "        mergedCaption = []\n",
    "        for cap in doc['caption']:\n",
    "            captionsList.append(cap)\n",
    "#             mergedCaption.append(cap)  \n",
    "#         captionsList.append(mergedCaption)\n",
    "#         captionsList.append(doc['caption'])\n",
    "#         captions = []\n",
    "\n",
    "\n",
    "    return titlesList, captionsList\n",
    "\n",
    "titlesList, captionsList = createDocList(rp.medDocs)\n",
    "print(rp.medDocs[0]['caption'])\n",
    "print(captionsList[1])\n",
    "# titlesList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2587\n"
     ]
    }
   ],
   "source": [
    "rp.bagOfWordsTitle, rp.bagOfWordsCaption ### = createBagsOfWOrds(rp.cleanedDocs)\n",
    "bow = set(rp.bagOfWordsTitle).union(set(rp.bagOfWordsCaption))\n",
    "print(len(bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-24a938f8fae7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# this steps generates word counts for the words in your docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mword_count_vector\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitlesList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitlesList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m387\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_count_vector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "#instantiate CountVectorizer() \n",
    "cv=CountVectorizer() \n",
    " \n",
    "# this steps generates word counts for the words in your docs \n",
    "word_count_vector=cv.fit_transform(titlesList)\n",
    "# print(titlesList[0][387])\n",
    "print(word_count_vector[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(docList):\n",
    "    vectorizer = TfidfVectorizer(lowercase = False, tokenizer = rp.preprocessContent)\n",
    "    vectors = vectorizer.fit_transform(docList)\n",
    "#     print(vectors)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "    df = pd.DataFrame(denselist, columns=feature_names)\n",
    "    return denselist, feature_names, df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tfidf, title_terms, title_df = computeTFIDF(titlesList)\n",
    "title_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_tfidf, caption_terms, caption_df = computeTFIDF(captionsList)\n",
    "print(caption_tfidf[0])\n",
    "caption_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capDicts(corpus):\n",
    "    captionsDict = {}\n",
    "    captionCount = 0\n",
    "    for i, doc in enumerate(corpus):\n",
    "        captionsDict[i] = len(doc['caption'])\n",
    "        \n",
    "    return captionsDict\n",
    "\n",
    "\n",
    "captions = capDicts(rp.cleanedDocs)\n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTotalTFIDF(corpus, alpha):\n",
    "    titlesList, captionsList = createDocList(corpus)\n",
    "    N = len(corpus)\n",
    "    title_tfidf, title_terms, title_df = computeTFIDF(titlesList)\n",
    "    caption_tfidf, caption_terms, caption_df = computeTFIDF(captionsList)\n",
    "    captions = capDicts(rp.cleanedDocs)\n",
    "    bow = set(title_terms).union(set(caption_terms))\n",
    "    n = len(caption_tfidf)\n",
    "    for i in range(N):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
