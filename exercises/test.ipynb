{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". Histologic section of adrenal metastatic disease (hematoxylin and eosin, ×).  Tumor cells arranged in solid nests infiltrating lymph node tissue. yes? as follows:\n",
      ". Histologic section of adrenal metastatic disease .  Tumor cells arranged in solid nests infiltrating lymph node tissue. yes? as follows:\n",
      ". Histologic section of adrenal metastatic disease .  Tumor cells arranged in solid nests infiltrating lymph node tissue. yes? as follows:\n",
      "Histologic\n",
      "section\n",
      "of\n",
      "adrenal\n",
      "metastatic\n",
      "disease\n",
      "Tumor\n",
      "cells\n",
      "arranged\n",
      "in\n",
      "solid\n",
      "nests\n",
      "infiltrating\n",
      "lymph\n",
      "node\n",
      "tissue\n",
      "yes\n",
      "as\n",
      "follows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'i',\n",
       " 's',\n",
       " 't',\n",
       " 'o',\n",
       " 'l',\n",
       " 'o',\n",
       " 'g',\n",
       " 'i',\n",
       " 'c',\n",
       " 's',\n",
       " 'e',\n",
       " 'c',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " 'o',\n",
       " 'f',\n",
       " 'a',\n",
       " 'd',\n",
       " 'r',\n",
       " 'e',\n",
       " 'n',\n",
       " 'a',\n",
       " 'l',\n",
       " 'm',\n",
       " 'e',\n",
       " 't',\n",
       " 'a',\n",
       " 's',\n",
       " 't',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 'e',\n",
       " 'a',\n",
       " 's',\n",
       " 'e',\n",
       " 'T',\n",
       " 'u',\n",
       " 'm',\n",
       " 'o',\n",
       " 'r',\n",
       " 'c',\n",
       " 'e',\n",
       " 'l',\n",
       " 'l',\n",
       " 's',\n",
       " 'a',\n",
       " 'r',\n",
       " 'r',\n",
       " 'a',\n",
       " 'n',\n",
       " 'g',\n",
       " 'e',\n",
       " 'd',\n",
       " 'i',\n",
       " 'n',\n",
       " 's',\n",
       " 'o',\n",
       " 'l',\n",
       " 'i',\n",
       " 'd',\n",
       " 'n',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " 's',\n",
       " 'i',\n",
       " 'n',\n",
       " 'f',\n",
       " 'i',\n",
       " 'l',\n",
       " 't',\n",
       " 'r',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'l',\n",
       " 'y',\n",
       " 'm',\n",
       " 'p',\n",
       " 'h',\n",
       " 'n',\n",
       " 'o',\n",
       " 'd',\n",
       " 'e',\n",
       " 't',\n",
       " 'i',\n",
       " 's',\n",
       " 's',\n",
       " 'u',\n",
       " 'e',\n",
       " 'y',\n",
       " 'e',\n",
       " 's',\n",
       " 'a',\n",
       " 's',\n",
       " 'f',\n",
       " 'o',\n",
       " 'l',\n",
       " 'l',\n",
       " 'o',\n",
       " 'w',\n",
       " 's']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "text = '1. Histologic section of adrenal metastatic disease (hematoxylin and eosin, ×100). 2 Tumor cells arranged in solid nests infiltrating lymph node tissue. yes? as follows:'\n",
    "\n",
    "x1 = re.sub('[0-9]+', '', text)\n",
    "print(x1)\n",
    "\n",
    "x2 = re.sub('\\(.*\\)', '', x1)\n",
    "print(x2)\n",
    "\n",
    "x3 = re.sub('\\<+/*\\w*/*\\>+', '', x2)\n",
    "print(x3)\n",
    "x4 = re.sub('[.,!?;:@]','',x3)\n",
    "x5 = x4.split()\n",
    "tokens= []\n",
    "for term in x5:\n",
    "    if term not in punctuation:\n",
    "        print(term)\n",
    "        tokens+=term\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, TweetTokenizer\n",
    "from string import punctuation\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def preprocess_document(content):\n",
    "    \"\"\"\n",
    "    Returns a list of tokens for a document's content. \n",
    "    Tokens should not contain punctuation and should be lower-cased.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(content)\n",
    "    tokens = []\n",
    "    for _sent in sentences:\n",
    "#         print(\"-------------------------------------1\")\n",
    "#         print(_sent)\n",
    "        remNumb = re.sub('[0-9]+', ' ', _sent)\n",
    "#         print(remNumb)\n",
    "        #remSymbols = re.sub('[.,!?;:@]',' ',remNumb)\n",
    "        remParantese = re.sub('\\([^()]*\\) | \\{[^{*}*]*\\} | \\[[^[]]*\\]', ' ', remNumb)\n",
    "        #print(remParantese)\n",
    "        #remSymbols = re.sub('[.,!?;:@\\\\{}[]()',' ',remParantese)\n",
    "        sent_tokens = tokenizer.tokenize(remParantese)\n",
    "        #print(sent_tokens)\n",
    "        sent_tokens = [_tok.lower() for _tok in sent_tokens if _tok not in punctuation]\n",
    "        tokens += sent_tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upper',\n",
       " 'graph',\n",
       " 'observed',\n",
       " 'lal',\n",
       " 'jaj',\n",
       " 'aj',\n",
       " 'alla',\n",
       " 'and',\n",
       " 'model',\n",
       " 'predicted',\n",
       " 'response-time',\n",
       " 'data',\n",
       " 'in',\n",
       " 'plasma',\n",
       " 'after',\n",
       " 'oral',\n",
       " 'administration',\n",
       " 'of',\n",
       " 'type',\n",
       " 'entrez-nucleotide',\n",
       " 'attrs',\n",
       " ':{',\n",
       " 'text',\n",
       " 'ly',\n",
       " 'term_id',\n",
       " 'term_text',\n",
       " 'ly',\n",
       " 'ly',\n",
       " 'to',\n",
       " 'human',\n",
       " 'volunteers',\n",
       " 'data',\n",
       " 'scanned',\n",
       " 'from',\n",
       " 'siemers',\n",
       " 'et',\n",
       " 'al',\n",
       " 'dataset',\n",
       " 'analyzed',\n",
       " 'with',\n",
       " 'a',\n",
       " 'dual',\n",
       " 'action',\n",
       " 'on',\n",
       " 'the',\n",
       " 'turnover',\n",
       " 'rate',\n",
       " 'of',\n",
       " 'response',\n",
       " 'eq',\n",
       " 'bottom',\n",
       " 'graph',\n",
       " 'concentration-response',\n",
       " 'plot',\n",
       " 'with',\n",
       " 'data',\n",
       " 'from',\n",
       " 'all',\n",
       " 'three',\n",
       " 'dose',\n",
       " 'groups',\n",
       " 'collated']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= \"Upper graph: observed {LAL{jaj aj}ALLA} (filled symbols) and model predicted (lines) response-time data in plasma after oral administration of {\\\"type\\\":\\\"entrez-nucleotide\\\",\\\"attrs\\\":{\\\"text\\\":\\\"LY450139\\\",\\\"term_id\\\":\\\"1258021836\\\",\\\"term_text\\\":\\\"LY450139\\\"}}LY450139 to human volunteers. Data scanned from Siemers et al. (18). Dataset analyzed with a dual action (inhibitory/stimulatory) on the turnover rate of response (Eq. 16). Bottom graph: concentration-response plot with data from all three dose groups collated\"\n",
    "tokens = preprocess_document(text)\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':{',\n",
       " 'aj',\n",
       " 'alla',\n",
       " 'and',\n",
       " 'after',\n",
       " 'administration',\n",
       " 'attrs',\n",
       " 'al',\n",
       " 'analyzed',\n",
       " 'a',\n",
       " 'action',\n",
       " 'all',\n",
       " 'bottom',\n",
       " 'concentration-response',\n",
       " 'collated',\n",
       " 'data',\n",
       " 'data',\n",
       " 'dataset',\n",
       " 'dual',\n",
       " 'data',\n",
       " 'dose',\n",
       " 'entrez-nucleotide',\n",
       " 'et',\n",
       " 'eq',\n",
       " 'from',\n",
       " 'from',\n",
       " 'graph',\n",
       " 'graph',\n",
       " 'groups',\n",
       " 'human',\n",
       " 'in',\n",
       " 'jaj',\n",
       " 'lal',\n",
       " 'ly',\n",
       " 'ly',\n",
       " 'ly',\n",
       " 'model',\n",
       " 'observed',\n",
       " 'oral',\n",
       " 'of',\n",
       " 'on',\n",
       " 'of',\n",
       " 'predicted',\n",
       " 'plasma',\n",
       " 'plot',\n",
       " 'response-time',\n",
       " 'rate',\n",
       " 'response',\n",
       " 'scanned',\n",
       " 'siemers',\n",
       " 'type',\n",
       " 'text',\n",
       " 'term_id',\n",
       " 'term_text',\n",
       " 'to',\n",
       " 'the',\n",
       " 'turnover',\n",
       " 'three',\n",
       " 'upper',\n",
       " 'volunteers',\n",
       " 'with',\n",
       " 'with']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from operator import itemgetter\n",
    "sortedTermsPostings = sorted(tokens,key=lambda x: x[0])\n",
    "sortedTermsPostings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = preprocess_document(open('../exercises/assets/medImages.jl').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, TweetTokenizer\n",
    "from string import punctuation\n",
    "tokenizer = TweetTokenizer()\n",
    "import regex\n",
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "def preprocess_document(content):\n",
    "    \"\"\"\n",
    "    Returns a list of tokens for a document's content. \n",
    "    Tokens should not contain punctuation and should be lower-cased.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(content)\n",
    "    tokens = []\n",
    "    for _sent in sentences:\n",
    "#         print(\"-------------------------------------1\")\n",
    "#         print(_sent)\n",
    "        remNumb = re.sub('[0-9]+', ' ', _sent)\n",
    "#         print(remNumb)\n",
    "        #remSymbols = re.sub('[.,!?;:@]',' ',remNumb)\n",
    "        remParantese = regex.sub(r'\\([^()]*+(?:(?R)[^()]*)*+\\)', '', remNumb) \n",
    "        remParantese2 = regex.sub('\\{(?:[^}{]|\\{[^}{]*\\})*\\}', '', remParantese) \n",
    "        #print(remParantese)\n",
    "        #remSymbols = re.sub('[.,!?;:@\\\\{}[]()',' ',remParantese)\n",
    "        sent_tokens = tokenizer.tokenize(remParantese2)\n",
    "        #print(sent_tokens)\n",
    "        sent_tokens = [_tok.lower() for _tok in sent_tokens if _tok not in punctuation]\n",
    "        tokens += sent_tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upper',\n",
       " 'graph',\n",
       " 'observed',\n",
       " 'fd',\n",
       " 'and',\n",
       " 'model',\n",
       " 'predicted',\n",
       " 'response-time',\n",
       " 'data',\n",
       " 'in',\n",
       " 'plasma',\n",
       " 'after',\n",
       " 'oral',\n",
       " 'administration',\n",
       " 'of',\n",
       " 'ly',\n",
       " 'to',\n",
       " 'human',\n",
       " 'volunteers',\n",
       " 'data',\n",
       " 'scanned',\n",
       " 'from',\n",
       " 'siemers',\n",
       " 'et',\n",
       " 'al',\n",
       " 'dataset',\n",
       " 'analyzed',\n",
       " 'with',\n",
       " 'a',\n",
       " 'dual',\n",
       " 'action',\n",
       " 'on',\n",
       " 'the',\n",
       " 'turnover',\n",
       " 'rate',\n",
       " 'of',\n",
       " 'response',\n",
       " 'eq',\n",
       " 'bottom',\n",
       " 'graph',\n",
       " 'concentration-response',\n",
       " 'plot',\n",
       " 'with',\n",
       " 'data',\n",
       " 'from',\n",
       " 'all',\n",
       " 'three',\n",
       " 'dose',\n",
       " 'groups',\n",
       " 'collated']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= \"Upper graph: observed {LAL {jaj aj} ALLA} fd (filled symbols) and model predicted (lines) response-time data in plasma after oral administration of {\\\"type\\\":\\\"entrez-nucleotide\\\",\\\"attrs\\\":{\\\"text\\\":\\\"LY450139\\\",\\\"term_id\\\":\\\"1258021836\\\",\\\"term_text\\\":\\\"LY450139\\\"}}LY450139 to human volunteers. Data scanned from Siemers et al. (18). Dataset analyzed with a dual action (inhibitory/stimulatory) on the turnover rate of response (Eq. 16). Bottom graph: concentration-response plot with data from all three dose groups collated\"\n",
    "tokens = preprocess_document(text)\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\((?:[^)(]|\\\\([^)(]*\\\\))*\\\\)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\((?:[^)(]|\\([^)(]*\\))*\\)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'21st',\n",
       " 'Data',\n",
       " 'Science',\n",
       " 'century',\n",
       " 'data',\n",
       " 'for',\n",
       " 'is',\n",
       " 'job',\n",
       " 'key',\n",
       " 'learning',\n",
       " 'machine',\n",
       " 'of',\n",
       " 'science',\n",
       " 'sexiest',\n",
       " 'the'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sentence = \"Data Science is the sexiest job of the 21st century\"\n",
    "second_sentence = \"machine learning is the key for data science\"\n",
    "#split so each word have their own string\n",
    "first_sentence = first_sentence.split(\" \")\n",
    "second_sentence = second_sentence.split(\" \")\n",
    "#join them to remove common duplicate words\n",
    "total= set(first_sentence).union(set(second_sentence))\n",
    "# print(total)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['science',\n",
       " '21st',\n",
       " 'sexiest',\n",
       " 'Data',\n",
       " 'century',\n",
       " 'key',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'Science',\n",
       " 'data',\n",
       " 'job']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# set(stopwords.words('english'))\n",
    "\n",
    "stopwords = ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "\n",
    "filtered_total = [w for w in total if not w in stopwords]\n",
    "filtered_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'science': 0,\n",
       " '21st': 1,\n",
       " 'sexiest': 1,\n",
       " 'Data': 1,\n",
       " 'century': 1,\n",
       " 'key': 0,\n",
       " 'machine': 0,\n",
       " 'learning': 0,\n",
       " 'Science': 1,\n",
       " 'data': 0,\n",
       " 'job': 1}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictA = dict.fromkeys(filtered_total, 0) \n",
    "wordDictB = dict.fromkeys(filtered_total, 0)\n",
    "for word in first_sentence:\n",
    "    if wordDictA.get(word) != None:\n",
    "        wordDictA[word]+=1\n",
    "\n",
    "for word in second_sentence:\n",
    "    if wordDictB.get(word) != None:\n",
    "        wordDictB[word]+=1\n",
    "    \n",
    "    \n",
    "wordDictA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21st</th>\n",
       "      <th>Data</th>\n",
       "      <th>Science</th>\n",
       "      <th>century</th>\n",
       "      <th>data</th>\n",
       "      <th>job</th>\n",
       "      <th>key</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>science</th>\n",
       "      <th>sexiest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   21st  Data  Science  century  data  job  key  learning  machine  science  \\\n",
       "0     1     1        1        1     0    1    0         0        0        0   \n",
       "1     0     0        0        0     1    0    1         1        1        1   \n",
       "\n",
       "   sexiest  \n",
       "0        1  \n",
       "1        0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'science': 0,\n",
       " '21st': 1,\n",
       " 'sexiest': 1,\n",
       " 'Data': 1,\n",
       " 'century': 1,\n",
       " 'key': 0,\n",
       " 'machine': 0,\n",
       " 'learning': 0,\n",
       " 'Science': 1,\n",
       " 'data': 0,\n",
       " 'job': 1}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# set(stopwords.words('english'))\n",
    "\n",
    "stopwords = ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "# wordDictA_f = [wordDictA_f[w[0]]=w[1] for w in wordDictA.items() if not w[0] in stopwords]\n",
    "wordDictA_f = {}\n",
    "for item in wordDictA.items():\n",
    "    if item[0] not in stopwords:\n",
    "        wordDictA_f[item[0]] = item[1]\n",
    "wordDictB_f = {}\n",
    "for item in wordDictB.items():\n",
    "    if item[0] not in stopwords:\n",
    "        wordDictB_f[item[0]] = item[1]\n",
    "wordDictA_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'science': 1,\n",
       " '21st': 0,\n",
       " 'sexiest': 0,\n",
       " 'Data': 0,\n",
       " 'century': 0,\n",
       " 'key': 1,\n",
       " 'machine': 1,\n",
       " 'learning': 1,\n",
       " 'Science': 0,\n",
       " 'data': 1,\n",
       " 'job': 0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictB_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>21st</td>\n",
       "      <td>sexiest</td>\n",
       "      <td>Data</td>\n",
       "      <td>century</td>\n",
       "      <td>key</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning</td>\n",
       "      <td>Science</td>\n",
       "      <td>data</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>science</td>\n",
       "      <td>21st</td>\n",
       "      <td>sexiest</td>\n",
       "      <td>Data</td>\n",
       "      <td>century</td>\n",
       "      <td>key</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning</td>\n",
       "      <td>Science</td>\n",
       "      <td>data</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1        2     3        4    5        6         7        8   \\\n",
       "0  science  21st  sexiest  Data  century  key  machine  learning  Science   \n",
       "1  science  21st  sexiest  Data  century  key  machine  learning  Science   \n",
       "\n",
       "     9    10  \n",
       "0  data  job  \n",
       "1  data  job  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA_f, wordDictB_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>21st</th>\n",
       "      <th>Data</th>\n",
       "      <th>Science</th>\n",
       "      <th>century</th>\n",
       "      <th>data</th>\n",
       "      <th>job</th>\n",
       "      <th>key</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>science</th>\n",
       "      <th>sexiest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   21st  Data  Science  century   data  job    key  learning  machine  \\\n",
       "0   0.1   0.1      0.1      0.1  0.000  0.1  0.000     0.000    0.000   \n",
       "1   0.0   0.0      0.0      0.0  0.125  0.0  0.125     0.125    0.125   \n",
       "\n",
       "   science  sexiest  \n",
       "0    0.000      0.1  \n",
       "1    0.125      0.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(corpusCount)\n",
    "    return(tfDict)\n",
    "#running our sentences through the tf function:\n",
    "tfFirst = computeTF(wordDictA, first_sentence)\n",
    "tfSecond = computeTF(wordDictB, second_sentence)\n",
    "#Converting to dataframe for visualization\n",
    "tf = pd.DataFrame([tfFirst, tfSecond])\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "#     print(idfDict)\n",
    "    for word, val in idfDict.items():\n",
    "#         print(word)\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
    "        \n",
    "    return(idfDict)\n",
    "#inputing our sentences in the log file\n",
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'science': 0.0,\n",
       " '21st': 0.03010299956639812,\n",
       " 'sexiest': 0.03010299956639812,\n",
       " 'Data': 0.03010299956639812,\n",
       " 'century': 0.03010299956639812,\n",
       " 'key': 0.0,\n",
       " 'machine': 0.0,\n",
       " 'learning': 0.0,\n",
       " 'Science': 0.03010299956639812,\n",
       " 'data': 0.0,\n",
       " 'job': 0.03010299956639812}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "#running our two sentences through the IDF:\n",
    "idfFirst = computeTFIDF(tfFirst, idfs)\n",
    "idfSecond = computeTFIDF(tfSecond, idfs)\n",
    "idfFirst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting it in a dataframe\n",
    "idf= pd.DataFrame([idfFirst, idfSecond])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
