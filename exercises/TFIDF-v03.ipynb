{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### imports\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, TweetTokenizer\n",
    "from string import punctuation\n",
    "import re\n",
    "import regex\n",
    "tokenizer = TweetTokenizer()\n",
    "from nltk.corpus import stopwords\n",
    "stopW = stopwords.words('english')\n",
    "# stopW = ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "# print(sorted(stopW))\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histologic section of adrenal metastatic disease (hematoxylin and eosin, Г—100). Tumor cells arranged in solid nests infiltrating lymph node tissue.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'articleId': 'PMC7282154',\n",
       " 'image_path': 'PMC7282154-6_i2376-0605-6-2-e50-f06.jpg',\n",
       " 'image_url': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7282154/bin/i2376-0605-6-2-e50-f06.jpg',\n",
       " 'articleUrl': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7282154/',\n",
       " 'articleTitle': 'RECURRENT INVASIVE DUCTAL BREAST CARCINOMA PRESENTING AS PRIMARY ADRENAL INSUFFICIENCY WITH ADRENAL CRISIS',\n",
       " 'caption': 'Histologic section of adrenal metastatic disease (hematoxylin and eosin, Г—100). Tumor cells arranged in solid nests infiltrating lymph node tissue.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### a method to Read a json file with img captions and article titles and parse it into set of documents\n",
    "\n",
    "def getDocs(sourcePath):\n",
    "    medDocs = []\n",
    "    sourceFile = open(sourcePath, 'r')\n",
    "\n",
    "    count = 1\n",
    "    for line in sourceFile:\n",
    "        medDocs.append(json.loads(line))\n",
    "        count += 1\n",
    "\n",
    "    sourceFile.close()\n",
    "    \n",
    "    # for k in range(1,count):\n",
    "    #     print(str(k) + \" : \" + medDocs[k]['docId'])\n",
    "    return medDocs\n",
    "\n",
    "\n",
    "sourcePath = 'assets/medImages.jl'\n",
    "medDocs = getDocs(sourcePath)\n",
    "print(medDocs[262]['caption'])\n",
    "medDocs[262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method that cleans the title and caption text in each document\n",
    "# the result is tokenized titles and caption without unwanted brackets, numbers, spaces, tags, unicode charts;\n",
    "# result includes no punctuation and stopwards and tokens with length less than 2 symbols\n",
    "# all tokens are lower case\n",
    "\n",
    "\n",
    "def preprocessContent(content):\n",
    "    sentences = sent_tokenize(content)\n",
    "    tokens = []\n",
    "    for sent in sentences:\n",
    "        # removes unicode\n",
    "        cleanedTokens = re.sub(r'[^\\x00-\\x7F]+', ' ', sent)\n",
    "        # removes menions\n",
    "        cleanedTokens = re.sub(r'@\\w+', '', cleanedTokens)\n",
    "        # removes numbers\n",
    "#         cleanedTokens = re.sub('[0-9]+', '', cleanedTokens)\n",
    "        # removes nested brackets \n",
    "        cleanedTokens = regex.sub(r'\\([^()]*+(?:(?R)[^()]*)*+\\)', '', cleanedTokens) \n",
    "        # removes nested currly brackets\n",
    "        cleanedTokens = regex.sub('\\{(?:[^}{]|\\{[^}{]*\\})*\\}', '', cleanedTokens) \n",
    "        # removes html tags\n",
    "        cleanedTokens = re.sub('\\<+/*\\w*/*\\>+', '', cleanedTokens)\n",
    "        # removes punctuation\n",
    "        cleanedTokens = re.sub(r'[%s]' % re.escape(punctuation), ' ', cleanedTokens)\n",
    "        # removes doubled spaces\n",
    "        cleanedTokens = re.sub(r'\\s{2,}', ' ', cleanedTokens)\n",
    "        sentTokens = tokenizer.tokenize(cleanedTokens)\n",
    "        # lower case each token and removes tokens with length less than 2\n",
    "        sentTokens = [tok.lower() for tok in sentTokens if len(tok) >2]\n",
    "        # removes stop words \n",
    "        sentTokens2 = [tok for tok in sentTokens if not tok.lower() in stopW ]\n",
    "        \n",
    "        ### implement stemming! play = played and/or stemming ?!?\n",
    "        tokens += sentTokens2\n",
    "    return tokens\n",
    "\n",
    "from copy import deepcopy\n",
    "def cleanDocs(medDocs):\n",
    "    cleanedDocs = deepcopy(medDocs)\n",
    "#     cleanedDocs = []\n",
    "    for i, doc in enumerate(cleanedDocs):\n",
    "        doc['articleTitle'] = preprocessContent(doc['articleTitle'] )\n",
    "        doc['caption'] = preprocessContent(doc['caption'])\n",
    "    return cleanedDocs\n",
    "\n",
    "cleanedDocs = cleanDocs(medDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n",
      "Histologic section of adrenal metastatic disease (hematoxylin and eosin, Г—100). Tumor cells arranged in solid nests infiltrating lymph node tissue.\n",
      "['histologic', 'section', 'adrenal', 'metastatic', 'disease', 'tumor', 'cells', 'arranged', 'solid', 'nests', 'infiltrating', 'lymph', 'node', 'tissue']\n"
     ]
    }
   ],
   "source": [
    "print(len(cleanedDocs))\n",
    "# cleanedDocs[262]\n",
    "# print(cleanedDocs[262]['articleTitle'])\n",
    "print(medDocs[262]['caption'])\n",
    "print(cleanedDocs[262]['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histologic section of adrenal metastatic disease (hematoxylin and eosin, Г—100). Tumor cells arranged in solid nests infiltrating lymph node tissue.\n",
      "Histologic section of adrenal metastatic disease (hematoxylin and eosin, Г—100). Tumor cells arranged in solid nests infiltrating lymph node tissue.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RECURRENT INVASIVE DUCTAL BREAST CARCINOMA PRESENTING AS PRIMARY ADRENAL INSUFFICIENCY WITH ADRENAL CRISIS'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createDocList(corpus):\n",
    "    titlesList = []\n",
    "    captionsList = []\n",
    "    for doc in corpus:\n",
    "        titlesList.append(doc['articleTitle'])\n",
    "        captionsList.append(doc['caption'])\n",
    "    return titlesList, captionsList\n",
    "\n",
    "titlesList, captionsList = createDocList(medDocs)\n",
    "print(medDocs[262]['caption'])\n",
    "print(captionsList[262])\n",
    "titlesList[262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x493 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "title_word_count_vector=cv.fit_transform(titlesList)\n",
    "title_tokens = cv.get_feature_names()\n",
    "title_word_count_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-5ca61e1ee90c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle_word_count_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtitle_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    402\u001b[0m                                          dtype=values.dtype, copy=False)\n\u001b[0;32m    403\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(title_word_count_vector, columns=title_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 3062)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_word_count_vector=cv.fit_transform(captionsList)\n",
    "\n",
    "caption_word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformerTitle=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformerTitle.fit(caption_word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformerCaption=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformerCaption.fit(caption_word_count_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print idf values \n",
    "df_idf = pd.DataFrame(tfidf_transformerTitle.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    " \n",
    "# sort ascending \n",
    "# df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-3ec14bc1fc27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtfidfTransformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmooth_idf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# tf-idf scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtfidfTitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitlesVector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "# count matrix \n",
    "# count_vector=cv.transform(captionsList) \n",
    "titlesVector = cv.transform(titlesList)\n",
    "captionsVector = cv.transform(captionsList)   \n",
    "tfidfTransformer = TfidfTransformer(smooth_idf=True)\n",
    "# tf-idf scores \n",
    "tfidfTitle = TfidfTransformer.transform(titlesVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_idf_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c6e67e4d706c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#get tfidf vector for first document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfirst_document_vector\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_idf_vector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m262\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#print the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_idf_vector' is not defined"
     ]
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names() \n",
    " \n",
    "#get tfidf vector for first document \n",
    "first_document_vector=tf_idf_vector[262] \n",
    " \n",
    "#print the scores \n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
