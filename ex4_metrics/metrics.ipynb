{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__“If you cannot measure it, you cannot improve it”__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline - having a labeled dataset and a search models at hand, evaluate performance of the models (how well was the user's information request met?)\n",
    "\n",
    "\n",
    "Here we __estimate the performance with respect to each particular query__. In classification we will just have a list of results and will compute the metrics just once, not for each query!\n",
    "\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold: [1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Pred: [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "doc_ids = list(range(1, 31))\n",
    "gold = [[1, 2, 6, 18, 20, 16, 24, 17, 3], \n",
    "        [9, 12, 4, 5, 1, 10, 22, 23, 25, 27, 11]]\n",
    "query_results = [[1, 5, 7, 15, 20, 2, 30, 21, 24, 4, 6, 18], \n",
    "                 [3, 9, 11, 12, 30, 7, 8, 4, 21, 22]]\n",
    "\n",
    "def to_vector(doc_ids, doc_set):\n",
    "    return [1 if doc in doc_set else 0 for doc in doc_ids]\n",
    "\n",
    "gold_v = [to_vector(doc_ids, _v) for _v in gold]\n",
    "predicted_v = [to_vector(doc_ids, _v) for _v in query_results]\n",
    "\n",
    "print(\"Gold:\", gold_v[0])\n",
    "print(\"Pred:\", predicted_v[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 in the vector of gold annotations means that the document at this position is relevant to the query.<br>\n",
    "1 in the vector of predictions means that our model considers the document at this position as relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix:\n",
    "<img src=\"img/cm.png\" width=\"400\">\n",
    "\n",
    "__Diagonals is what we want to improve/increase!__\n",
    "\n",
    "__Exercise__: Calculate the CF for the queries:<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "[[15  6]\n",
      " [ 3  6]]\n",
      "Query 1:\n",
      "[[14  5]\n",
      " [ 6  5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    print(confusion_matrix(gold_v[i], predicted_v[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy - how many of the retrieved results are correct?\n",
    "\n",
    "$$\\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "__Exercise__ : Calculate the accuracy for the two queries<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "0.7\n",
      "Query 1:\n",
      "0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    print(accuracy_score(gold_v[i], predicted_v[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993\n",
      "0.995\n"
     ]
    }
   ],
   "source": [
    "# Why don't we just use accuracy?!\n",
    "test_dog_ids = list(range(1000))\n",
    "some_gold = [1, 2, 3, 4, 5]\n",
    "print(accuracy_score(to_vector(test_dog_ids, some_gold), to_vector(test_dog_ids, [1, 4, 6, 10, 11, 7])))\n",
    "print(accuracy_score(to_vector(test_dog_ids, some_gold), to_vector(test_dog_ids, [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In real IR systems we have __thousands of documents__. Thus, accuracy will cause our IR method to return __NO RESULTS__.\n",
    "- The change __improvements__ in the IR method are __less visible__ - we already have an accuracy of 0.995!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "<img src=\"img/cm_pr.png\" width=\"400\">\n",
    "\n",
    "Precision : How many of the retrieved results were useful? <br>\n",
    "$$Precision = \\frac{TP}{TP + FP}$$<br>  \n",
    "Recall : Were there any useful pages left not retrieved?  <br>\n",
    "$$Recall = \\frac{TP}{TP + FN}$$ \n",
    "\n",
    "__Exercise:__ \n",
    "- Compute Precision and Recall for the queries:<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11 <br>\n",
    "\n",
    "- What does it mean to have a precision = 1/ recall = 1 ?\n",
    "- When does precision decrease? When does recall decrease?\n",
    "- When do we get the highest recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "Precision: 0.5\n",
      "Recall: 0.6666666666666666\n",
      "Query 1:\n",
      "Precision: 0.5\n",
      "Recall: 0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    print(\"Precision:\", precision_score(gold_v[i], predicted_v[i]))\n",
    "    print(\"Recall:\", recall_score(gold_v[i], predicted_v[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which of the metrics is more important? - Usually depends on the business requirements.\n",
    "- We can also __combine Precision and Recall__, using their harmonic mean! \n",
    "\n",
    "## F1 score\n",
    "$$ F_{\\beta} = \\frac{(\\beta^{2}+1)PR}{\\beta^{2}P+R} $$\n",
    "\n",
    "Most common F1:\n",
    "$$ F_{1} = \\frac{2PR}{P+R} $$\n",
    "\n",
    "\n",
    "__Exercise__: \n",
    "- Compute F1 for the queries.<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11\n",
    "\n",
    "- Does the order of the results made the user’s search for information easier or harder? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "F1: 0.5714285714285715\n",
      "Query 1:\n",
      "F1: 0.47619047619047616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    print(\"F1:\", f1_score(gold_v[i], predicted_v[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics with account for position\n",
    "- So far : we didn't account for the __position of the correct relevant documents__ in the returned list of documents!\n",
    "- Example: If your __first page contains 20 items__, you might want to __optimize P@20, R@20__.\n",
    "\n",
    "__Exercise__: Compute P@N, R@N for N= 1, 2, 3, 4, 5<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "N: 1, Precision: 1.0, Recall: 0.1111111111111111\n",
      "N: 2, Precision: 0.5, Recall: 0.1111111111111111\n",
      "N: 3, Precision: 0.3333333333333333, Recall: 0.1111111111111111\n",
      "N: 4, Precision: 0.25, Recall: 0.1111111111111111\n",
      "N: 5, Precision: 0.4, Recall: 0.2222222222222222\n",
      "N: 6, Precision: 0.5, Recall: 0.3333333333333333\n",
      "N: 7, Precision: 0.42857142857142855, Recall: 0.3333333333333333\n",
      "Query 1:\n",
      "N: 1, Precision: 0.0, Recall: 0.0\n",
      "N: 2, Precision: 0.5, Recall: 0.09090909090909091\n",
      "N: 3, Precision: 0.6666666666666666, Recall: 0.18181818181818182\n",
      "N: 4, Precision: 0.75, Recall: 0.2727272727272727\n",
      "N: 5, Precision: 0.6, Recall: 0.2727272727272727\n",
      "N: 6, Precision: 0.5, Recall: 0.2727272727272727\n",
      "N: 7, Precision: 0.42857142857142855, Recall: 0.2727272727272727\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    for n in range(1, 8):\n",
    "        print(\"N:\", n, end=', ')\n",
    "        print(\"Precision:\", precision_score(gold_v[i], to_vector(doc_ids, query_results[i][:n])), end=', ')\n",
    "        print(\"Recall:\", recall_score(gold_v[i], to_vector(doc_ids, query_results[i][:n])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve: compute the precision achieved taking just top N of the returned results, i.e. precision at different recall levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.fixes import signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAEuVJREFUeJzt3X+QXWd93/H3B/knxpGjLOowloxMkJJoHECgGjPMJGYgHtuTym2HEGvKgKmLGooDlITWmXQMddrpBEqTNnFK1DGFeBqMYSZESZW4jeugNEFUcs0vm8ijChsLk7GNHaeJftgi3/5xrp5uVqvds9aee1er92vmjs4599lzvnpmdz97nnPOc1NVSJIE8IJJFyBJWjoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJas6adAELNTU1VevWrZt0GZJ0WrnvvvuerKoXz9dusFBI8nHgx4HHq+qyWd4P8O+Ba4FDwA1V9b/n2++6devYu3fvYpcrSctakkf6tBty+OgTwNVzvH8NsH702gb8xwFrkST1MFgoVNUu4Kk5mlwH/EZ1dgMXJXnJUPVIkuY3yWsKFwOPTls/ONr27bm+6MgReOihIcua3apVMDU1/uNK0jhNMhQyy7ZZ5/FOso1uiImpqZexa9eQZZ3o6NEuFLZuHe9xJWncJhkKB4G109bXAI/N1rCqtgPbATZs2FybNg1f3HSPPAJPzTUQJknLxCSfU9gBvC2dK4BnqmrOoSNJ0rCGvCX1U8CVwFSSg8AHgbMBqupjwE6621H3092S+o6hapEk9TNYKFTVnCPw1X0O6LuHOr4kaeGc5kKS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpGbQUEhydZJ9SfYnuXmW9y9Jcm+S+5N8Jcm1Q9YjSZrbYKGQZAVwG3ANsBHYmmTjjGb/ArirqjYB1wO/NlQ9kqT5DXmmcDmwv6oOVNWzwJ3AdTPaFPA9o+WVwGMD1iNJmsdZA+77YuDRaesHgdfOaPMh4L8l+WngAuBNs+0oyTZgG8Dq1ZcseqGSpM6QZwqZZVvNWN8KfKKq1gDXAnckOaGmqtpeVZuravPKlS8eoFRJEgwbCgeBtdPW13Di8NCNwF0AVfUF4DxgasCaJElzGDIU9gDrk1ya5By6C8k7ZrT5JvBGgCQ/RBcKTwxYkyRpDoOFQlUdA24C7ga+TneX0QNJbk2yZdTsZ4B3Jvky8CnghqqaOcQkSRqTIS80U1U7gZ0ztt0ybflB4PVD1iBJ6s8nmiVJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTmrEkXcDo4dAgOH4aHHhr/sVetgqmp8R9X0pnJUOjpyBHYtWu8xzx6tAuFrVvHe1xJZy5DoacjR2DTpvEe85FH4KmnxntMSWc2rylIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVIzaCgkuTrJviT7k9x8kjZvSfJgkgeS/OaQ9UiS5jbYE81JVgC3AT8GHAT2JNlRVQ9Oa7Me+Dng9VX1dJLVQ9UjSZrfkGcKlwP7q+pAVT0L3AlcN6PNO4HbquppgKp6fMB6JEnz6H2mkORi4KXTv6aq5poi7mLg0WnrB4HXzmizYbTvPwZWAB+qqt/vW5MkaXH1CoUkvwj8JPAg8N3R5gLmCoXMsq1mOf564EpgDfBHSS6rqj+fcfxtwDaA1asv6VOyJOl56Hum8HeBH6iqowvY90Fg7bT1NcBjs7TZXVXPAd9Iso8uJPZMb1RV24HtABs2bJ4ZLJKkRdL3msIB4OwF7nsPsD7JpUnOAa4Hdsxo8zngDQBJpuiGkw4s8DiSpEXS90zhEPClJPcA7Wyhqt5zsi+oqmNJbgLuprte8PGqeiDJrcDeqtoxeu+qJMeHpT5QVd95nv8XSdIp6hsKOzjxr/x5VdVOYOeMbbdMWy7g/aOXJGnCeoVCVX1yNAS0YbRp3+g6gCRpGel799GVwCeBh+nuKlqb5O3z3JIqSTrN9B0++ihwVVXtA0iyAfgU8JqhCpMkjV/fUDj7eCAAVNVDSRZ6N5J0Uk8+CU89NZljr1oFU1OTOba01PQNhb1JbgfuGK3/A+C+YUrSmeipp+BP/gSOHRvvcY8e7UJh69bxHldaqvqGwruAdwPvobumsAv4taGK0pnp2DHYtGm8x3zkkcmdoUhLUd+7j44C/270kiQtU3OGQpK7quotSb7KifMWUVWvGKwySdLYzXem8N7Rvz8+dCGSpMmbc+6jqvr2aPFJ4NGqegQ4F3glJ05uJ0k6zfWdEG8XcN7oMxXuAd4BfGKooiRJk9E3FFJVh4C/D/xKVf09YONwZUmSJqF3KCR5Hd3zCf91tG2wz3eWJE1G31B4H/BzwG+Npr9+GXDvcGVJkiah73MKnwc+P239AN2DbJKkZWS+5xR+uarel+R3mP05hS2DVaaJmcQ8RIcOjfd4kmY335nC8bmO/u3QhSxlF1wA558/6SrGZ1LzEJ177niPJ+lEc4ZCVR2f9G4vcLiq/hogyQq65xXOCJdc0r3OJJOYh0jS5PW90HwP8MJp6+cDf7D45UiSJqlvKJxXVX95fGW0/MI52kuSTkN9Q+Gvkrz6+EqS1wCHhylJkjQpfR9Aex/wmSTH5zt6CfCTw5QkSZqUvs8p7Enyg8AP0H3Izp9W1XODViZJGrtew0dJXgj8c+C9VfVVYF0Sp9OWpGWm7zWF/ww8C7xutH4Q+FeDVCRJmpi+ofD9VfVh4DmAqjpMN4wkSVpG+obCs0nOZzTVRZLvB44OVpUkaSL63n30QeD3gbVJ/gvweuCGoYqSJE3GvKGQJMCf0n3AzhV0w0bvraonB65NkjRm84ZCVVWSz1XVa/j/H7AjSVqG+g4f7U7yt6tqz6DV6G84dAgOH4aHHhr/cSWdmfqGwhuAn0ryMPBXdENIVVWvGKowdY4cgV27xn9cp7GWzkx9Q+GaQavQSR054hTWksZnvk9eOw/4KeDlwFeB26tqzB+9Ikkal/meU/gksJkuEK4BPrqQnSe5Osm+JPuT3DxHuzcnqSSbF7J/SdLimm/4aGNV/TBAktuB/9V3x6NPZ7sN+DG6aTH2JNlRVQ/OaHch8B7giwspXJK0+OY7U2gzoT6PYaPLgf1VdaCqngXuBK6bpd0vAB8Gjixw/5KkRTZfKLwyyV+MXv8XeMXx5SR/Mc/XXgw8Om394Ghbk2QTsLaqfnfBlUuSFt2cw0dVteIU9j3bhHnV3kxeAPwSPabLSLIN2AawevUlp1CSJGkufSfEez4OAmunra8BHpu2fiFwGfCHo+cfrgB2zHaxuaq2V9Xmqtq8cuWLByxZks5sQ4bCHmB9kkuTnANcD+w4/mZVPVNVU1W1rqrWAbuBLVW1d8CaJElzGCwURhembwLuBr4O3FVVDyS5NcmWoY4rSXr++j7R/LxU1U5g54xtt5yk7ZVD1iJJmt+Qw0eSpNPMoGcK0ung6NHxz0QrDeH882Ht2vnbzcVQ0Blt5Ur4sz+bzEy00mJbtcpQkE7JRRfBa1876SqkxfHEE6e+D68pSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFJawCy7o7juWpHHxltQl7JJLupckjYtnCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSmkFDIcnVSfYl2Z/k5lnef3+SB5N8Jck9SV46ZD2SpLkNFgpJVgC3AdcAG4GtSTbOaHY/sLmqXgF8FvjwUPVIkuY35JnC5cD+qjpQVc8CdwLXTW9QVfdW1aHR6m5gzYD1SJLmMWQoXAw8Om394GjbydwI/N5sbyTZlmRvkr3PPPPEIpYoSZpuyFDILNtq1obJW4HNwEdme7+qtlfV5qravHLlixexREnSdGcNuO+DwNpp62uAx2Y2SvIm4OeBH62qowPWI0max5BnCnuA9UkuTXIOcD2wY3qDJJuAXwe2VNXjA9YiSephsFCoqmPATcDdwNeBu6rqgSS3JtkyavYR4EXAZ5J8KcmOk+xOkjQGQw4fUVU7gZ0ztt0ybflNQx5fkrQwPtEsSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagYNhSRXJ9mXZH+Sm2d5/9wknx69/8Uk64asR5I0t8FCIckK4DbgGmAjsDXJxhnNbgSerqqXA78E/OJQ9UiS5jfkmcLlwP6qOlBVzwJ3AtfNaHMd8MnR8meBNybJgDVJkuYwZChcDDw6bf3gaNusbarqGPAM8H0D1iRJmsNZA+57tr/463m0Ick2YNto7bnNm7/34VOsbRk4uhLOfWbSVUyWfdCxHzr2Axy+EI5+6yRvvrTPHoYMhYPA2mnra4DHTtLmYJKzgJXAUzN3VFXbge0ASfZWPb15kIpPI10/HDqj+8E+6NgPHfvheB/UKfXBkMNHe4D1SS5Ncg5wPbBjRpsdwNtHy28G/kdVnXCmIEkaj8HOFKrqWJKbgLuBFcDHq+qBJLcCe6tqB3A7cEeS/XRnCNcPVY8kaX5DDh9RVTuBnTO23TJt+QjwEwvc7fZFKG05sB/sg+Psh479sAh9EEdrJEnHOc2FJKlZsqHgFBm9+uD9SR5M8pUk9yTpdcvZ6Wa+fpjW7s1JKsmyvAOlTz8kecvoe+KBJL857hqH1uNn4pIk9ya5f/Rzce0k6hxSko8neTzJ107yfpL8h1EffSXJqxd0gKpaci+6C9P/B3gZcA7wZWDjjDb/BPjYaPl64NOTrnsCffAG4IWj5Xcttz7o2w+jdhcCu4DdwOZJ1z2h74f1wP3A947WV0+67gn0wXbgXaPljcDDk657gH74EeDVwNdO8v61wO/RPQd2BfDFhex/qZ4pOEVGjz6oqnur6tBodTfdsyDLTZ/vBYBfAD4MHBlncWPUpx/eCdxWVU8DVNXjY65xaH36oIDvGS2v5MRno057VbWLWZ7nmuY64Deqsxu4KMlL+u5/qYaCU2T064PpbqT762C5mbcfkmwC1lbV746zsDHr8/2wAdiQ5I+T7E5y9diqG48+ffAh4K1JDtLd+fjT4yltSVno746/YdBbUk/Bok2RcRrr/f9L8lZgM/Cjg1Y0GXP2Q5IX0M2we8O4CpqQPt8PZ9ENIV1Jd9b4R0kuq6o/H7i2cenTB1uBT1TVR5O8ju45qMuq6q+HL2/JOKXfjUv1TGEhU2Qw1xQZp7E+fUCSNwE/D2ypqqNjqm2c5uuHC4HLgD9M8jDdGOqOZXixue/PxG9X1XNV9Q1gH11ILBd9+uBG4C6AqvoCcB4wNZbqlo5evztOZqmGglNk9OiD0bDJr9MFwnIbPz5uzn6oqmeqaqqq1lXVOrprK1uqau9kyh1Mn5+Jz9HdfECSKbrhpANjrXJYffrgm8AbAZL8EF0oPDHWKidvB/C20V1IVwDPVNW3+37xkhw+KqfI6NsHHwFeBHxmdI39m1W1ZWJFD6BnPyx7PfvhbuCqJA8C3wU+UFXfmVzVi6tnH/wM8J+S/FO6IZMbltkfiyT5FN0Q4dTo2skHgbMBqupjdNdSrgX2A4eAdyxo/8usvyRJp2CpDh9JkibAUJAkNYaCJKkxFCRJjaEgSWoMBWmGJN9N8qUkX0vyO0kuWuT935DkV0fLH0rys4u5f+lUGArSiQ5X1auq6jK6Z2DePemCpHExFKS5fYFpk4kl+UCSPaN56v/ltO1vG237cpI7Rtv+zuizPu5P8gdJ/tYE6pcWZEk+0SwtBUlW0E2ZcPto/Sq6uYQup5t0bEeSHwG+Qzf/1Our6skkq0a7+J/AFVVVSf4R8M/onriVlixDQTrR+Um+BKwD7gP++2j7VaPX/aP1F9GFxCuBz1bVkwBVdXxixjXAp0dz2Z8DfGMs1UunwOEj6USHq+pVwEvpfpkfv6YQ4N+Mrje8qqpeXlW3j7bPNl/MrwC/WlU/DPxjusnZpCXNUJBOoqqeAd4D/GySs+kmYvuHSV4EkOTiJKuBe4C3JPm+0fbjw0crgW+Nlt+OdBpw+EiaQ1Xdn+TLwPVVdcdoOuYvjGal/UvgraOZOv818Pkk36UbXrqB7lPAPpPkW3RTel86if+DtBDOkipJahw+kiQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKk5v8Bg/dJ4zmK5sYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    rankings = [query_results[i].index(j)/len(doc_ids) if j in query_results[i] else 0 for j in doc_ids]\n",
    "    precision, recall, _ = precision_recall_curve(gold_v[i], rankings)\n",
    "    \n",
    "    step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.02])\n",
    "    plt.xlim([0.0, 1.02])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More metrics:\n",
    "- __R-Precision__ - having 20 relevant documents for a query, measure precision at 20, R=20. Dynamic metric, which depends on the number of relevant documents for each query.\n",
    "    - A perfect system can score 1.0 over all queries.\n",
    "- __Mean Reciprocal Rank__\n",
    "\n",
    " $$\\text{MRR} = \\frac{1}{|Q|} \\sum_{i=1}^{|Q|}\\sum_{j=1}^{|RelD_{Q}|} \\frac{1}{\\text{rank}_{i,j}}. $$\n",
    "    - Usually computed only for the first relevant document!\n",
    "    - Reciprocal Rank for the first correct document - returned __at position 1 = 1, at position 2 = 1/2,__ etc.<br>\n",
    "    - The reciprocal rank is low if a relevant document is returned at the end of the list with results.\n",
    "- __Mean Average Precision__ - average of the precision value obtained for the top k documents, each time a relevant doc is retrieved\n",
    "     - Compute __MEAN over queries__\n",
    "     - For each query, compute: __AVERAGE of the Precision@N__, computed at each relevant document\n",
    "$$ AvgP = \\frac{\\sum_{N=1}^{|D_{Q}|} (P@N \\times rel@N)}{RelD_{Q}} $$\n",
    "\n",
    "- Even more: __discounted cumulative gain__ (DCG) - when relevance is not binary, but we may measure a degree of relevance - e.g. exact match, relevant, not relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Compute MRR, MAP and R-precision for: <br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to navigate your efforts depending on the metrics?\n",
    "- Use the selected metric to improve the performance on the validation set.\n",
    "- Once tuned, estimate the performance on the test set, too. \n",
    "- The train, validation and test scores w.r.t the selected metric should help you to estimate bias/variance.\n",
    "- Then, it would be easier to decide whether to get more data/make more complex/simple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online metrics - see how users interact with your system\n",
    "\n",
    "- Session abandonment rate and session success rate\n",
    "- Click-through rate (CTR) \n",
    "- Satisfaction of a click - how much time is spent on a URL\n",
    "- Time before clicking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available Datasets for Experiments with evaluation metrics:\n",
    "(only for classification) <br>\n",
    "https://www.nltk.org/book/ch02.html <br>\n",
    "https://archive.ics.uci.edu/ml/datasets.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
