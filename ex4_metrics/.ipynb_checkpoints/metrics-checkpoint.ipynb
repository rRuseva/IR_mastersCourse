{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__“If you cannot measure it, you cannot improve it”__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline - having a labeled dataset and a search models at hand, evaluate performance of the models (how well was the user's information request met?)\n",
    "\n",
    "\n",
    "Here we __estimate the performance with respect to each particular query__. In classification we will just have a list of results and will compute the metrics just once, not for each query!\n",
    "\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold: [1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "Pred: [1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "doc_ids = list(range(1, 31))\n",
    "### д\n",
    "gold = [[1, 2, 6, 18, 20, 16, 24, 17, 3], \n",
    "        [9, 12, 4, 5, 1, 10, 22, 23, 25, 27, 11]]\n",
    "query_results = [[1, 5, 7, 15, 20, 2, 30, 21, 24, 4, 6, 18], \n",
    "                 [3, 9, 11, 12, 30, 7, 8, 4, 21, 22]]\n",
    "\n",
    "def to_vector(doc_ids, doc_set):\n",
    "    return [1 if doc in doc_set else 0 for doc in doc_ids]\n",
    "\n",
    "gold_v = [to_vector(doc_ids, _v) for _v in gold]\n",
    "predicted_v = [to_vector(doc_ids, _v) for _v in query_results]\n",
    "\n",
    "print(\"Gold:\", gold_v[0])\n",
    "print(\"Pred:\", predicted_v[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 in the vector of gold annotations means that the document at this position is relevant to the query.<br>\n",
    "1 in the vector of predictions means that our model considers the document at this position as relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix:\n",
    "<img src=\"img/cm.png\" width=\"400\">\n",
    "\n",
    "__Diagonals is what we want to improve/increase!__\n",
    "\n",
    "__Exercise__: Calculate the CF for the queries:<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "[[15  6]\n",
      " [ 3  6]]\n",
      "Query 1:\n",
      "[[14  5]\n",
      " [ 6  5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    print(confusion_matrix(gold_v[i], predicted_v[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy - how many of the retrieved results are correct?\n",
    "\n",
    "$$\\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "__Exercise__ : Calculate the accuracy for the two queries<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "0.7\n",
      "Query 1:\n",
      "0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    print(accuracy_score(gold_v[i], predicted_v[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993\n",
      "0.995\n"
     ]
    }
   ],
   "source": [
    "# Why don't we just use accuracy?!\n",
    "test_dog_ids = list(range(1000))\n",
    "some_gold = [1, 2, 3, 4, 5]\n",
    "print(accuracy_score(to_vector(test_dog_ids, some_gold), to_vector(test_dog_ids, [1, 4, 6, 10, 11, 7])))\n",
    "print(accuracy_score(to_vector(test_dog_ids, some_gold), to_vector(test_dog_ids, [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In real IR systems we have __thousands of documents__. Thus, accuracy will cause our IR method to return __NO RESULTS__.\n",
    "- The change __improvements__ in the IR method are __less visible__ - we already have an accuracy of 0.995!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall\n",
    "<img src=\"img/cm_pr.png\" width=\"400\">\n",
    "\n",
    "Precision : How many of the retrieved results were useful? <br>\n",
    "$$Precision = \\frac{TP}{TP + FP}$$<br>  \n",
    "Recall : Were there any useful pages left not retrieved?  <br>\n",
    "$$Recall = \\frac{TP}{TP + FN}$$ \n",
    "\n",
    "__Exercise:__ \n",
    "- Compute Precision and Recall for the queries:<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11 <br>\n",
    "\n",
    "- What does it mean to have a precision = 1/ recall = 1 ?\n",
    "- When does precision decrease? When does recall decrease?\n",
    "- When do we get the highest recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "Precision: 0.5\n",
      "Recall: 0.6666666666666666\n",
      "Query 1:\n",
      "Precision: 0.5\n",
      "Recall: 0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    print(\"Precision:\", precision_score(gold_v[i], predicted_v[i]))\n",
    "    print(\"Recall:\", recall_score(gold_v[i], predicted_v[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which of the metrics is more important? - Usually depends on the business requirements.\n",
    "- We can also __combine Precision and Recall__, using their harmonic mean! \n",
    "\n",
    "## F1 score\n",
    "$$ F_{\\beta} = \\frac{(\\beta^{2}+1)PR}{\\beta^{2}P+R} $$\n",
    "\n",
    "Most common F1:\n",
    "$$ F_{1} = \\frac{2PR}{P+R} $$\n",
    "\n",
    "\n",
    "__Exercise__: \n",
    "- Compute F1 for the queries.<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11\n",
    "\n",
    "- Does the order of the results made the user’s search for information easier or harder? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "F1: 0.5714285714285715\n",
      "Query 1:\n",
      "F1: 0.47619047619047616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    print(\"F1:\", f1_score(gold_v[i], predicted_v[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics with account for position\n",
    "- So far : we didn't account for the __position of the correct relevant documents__ in the returned list of documents!\n",
    "- Example: If your __first page contains 20 items__, you might want to __optimize P@20, R@20__.\n",
    "\n",
    "__Exercise__: Compute P@N, R@N for N= 1, 2, 3, 4, 5<br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n",
      "N: 1, Precision: 1.0, Recall: 0.1111111111111111\n",
      "N: 2, Precision: 0.5, Recall: 0.1111111111111111\n",
      "N: 3, Precision: 0.3333333333333333, Recall: 0.1111111111111111\n",
      "N: 4, Precision: 0.25, Recall: 0.1111111111111111\n",
      "N: 5, Precision: 0.4, Recall: 0.2222222222222222\n",
      "N: 6, Precision: 0.5, Recall: 0.3333333333333333\n",
      "N: 7, Precision: 0.42857142857142855, Recall: 0.3333333333333333\n",
      "Query 1:\n",
      "N: 1, Precision: 0.0, Recall: 0.0\n",
      "N: 2, Precision: 0.5, Recall: 0.09090909090909091\n",
      "N: 3, Precision: 0.6666666666666666, Recall: 0.18181818181818182\n",
      "N: 4, Precision: 0.75, Recall: 0.2727272727272727\n",
      "N: 5, Precision: 0.6, Recall: 0.2727272727272727\n",
      "N: 6, Precision: 0.5, Recall: 0.2727272727272727\n",
      "N: 7, Precision: 0.42857142857142855, Recall: 0.2727272727272727\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    for n in range(1, 8):\n",
    "        print(\"N:\", n, end=', ')\n",
    "        print(\"Precision:\", precision_score(gold_v[i], to_vector(doc_ids, query_results[i][:n])), end=', ')\n",
    "        print(\"Recall:\", recall_score(gold_v[i], to_vector(doc_ids, query_results[i][:n])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve: compute the precision achieved taking just top N of the returned results, i.e. precision at different recall levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.fixes import signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(\"Query {}:\".format(i))\n",
    "    rankings = [query_results[i].index(j)/len(doc_ids) if j in query_results[i] else 0 for j in doc_ids]\n",
    "    precision, recall, _ = precision_recall_curve(gold_v[i], rankings)\n",
    "    \n",
    "    step_kwargs = ({'step': 'post'} if 'step' in signature(plt.fill_between).parameters else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.02])\n",
    "    plt.xlim([0.0, 1.02])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More metrics:\n",
    "- __R-Precision__ - having 20 relevant documents for a query, measure precision at 20, R=20. Dynamic metric, which depends on the number of relevant documents for each query.\n",
    "    - A perfect system can score 1.0 over all queries.\n",
    "- __Mean Reciprocal Rank__\n",
    "\n",
    " $$\\text{MRR} = \\frac{1}{|Q|} \\sum_{i=1}^{|Q|}\\sum_{j=1}^{|RelD_{Q}|} \\frac{1}{\\text{rank}_{i,j}}. $$\n",
    "    - Usually computed only for the first relevant document!\n",
    "    - Reciprocal Rank for the first correct document - returned __at position 1 = 1, at position 2 = 1/2,__ etc.<br>\n",
    "    - The reciprocal rank is low if a relevant document is returned at the end of the list with results.\n",
    "- __Mean Average Precision__ - average of the precision value obtained for the top k documents, each time a relevant doc is retrieved\n",
    "     - Compute __MEAN over queries__\n",
    "     - For each query, compute: __AVERAGE of the Precision@N__, computed at each relevant document\n",
    "$$ AvgP = \\frac{\\sum_{N=1}^{|D_{Q}|} (P@N \\times rel@N)}{RelD_{Q}} $$\n",
    "\n",
    "- Even more: __discounted cumulative gain__ (DCG) - when relevance is not binary, but we may measure a degree of relevance - e.g. exact match, relevant, not relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Compute MRR, MAP and R-precision for: <br>\n",
    "Q1 : __D1__, D5, D7, D15, __D20__, __D2__, D30, D21, __D24__, D4, __D6__, __D18__ | GOLD: D1, D2, D6, D18, D20, D16, D24, D17, 3<br>\n",
    "Q2 : D3, __D9__, __D11__, __D12__, D30, D7, D8, D4, D21, __D22__ | GOLD: D9, D12, D4, D5, D1, D10, D22, D23, D25, D27, D11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to navigate your efforts depending on the metrics?\n",
    "- Use the selected metric to improve the performance on the validation set.\n",
    "- Once tuned, estimate the performance on the test set, too. \n",
    "- The train, validation and test scores w.r.t the selected metric should help you to estimate bias/variance.\n",
    "- Then, it would be easier to decide whether to get more data/make more complex/simple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online metrics - see how users interact with your system\n",
    "\n",
    "- Session abandonment rate and session success rate\n",
    "- Click-through rate (CTR) \n",
    "- Satisfaction of a click - how much time is spent on a URL\n",
    "- Time before clicking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available Datasets for Experiments with evaluation metrics:\n",
    "(only for classification) <br>\n",
    "https://www.nltk.org/book/ch02.html <br>\n",
    "https://archive.ics.uci.edu/ml/datasets.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
